{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mój grid search 3 do logs: python + deep learning + postgresql + early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jan  2 18:07:31 2019\n",
    "\n",
    "@author: bondi\n",
    "\"\"\"\n",
    "import sys\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Softmax, Activation, Dropout\n",
    "from keras.activations import relu\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers import scikit_learn\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import psycopg2\n",
    "import psycopg2.extras # cursor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "#%%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to connect\n",
    "try:\n",
    "    conn = psycopg2.connect(host='192.168.0.101', user='bartek', password='Aga', database='logs', port=5432)\n",
    "except:\n",
    "    print (\"I am unable to connect to the database.\")\n",
    "\n",
    "\n",
    "# utf8\n",
    "conn.set_client_encoding('UTF8')\n",
    "\n",
    "# cursor\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25113, 11)\n",
      "(20090, 5) (5023, 5) (20090,) (5023,)\n"
     ]
    }
   ],
   "source": [
    "# Dane\n",
    "\n",
    "logs_df = pd.read_sql_query('select * from akuratne_25k', conn)\n",
    "print(logs_df.shape)\n",
    "logs_df.head()\n",
    "\n",
    "logs_df.shape\n",
    "\n",
    "\n",
    "features = ['rank_w_ip' , 'avg_id_rows_current' , 'id_parity' , 'rank_w_ip_parity' , 'the_same_parity']\n",
    "features\n",
    "\n",
    "\n",
    "target = 'target_1'\n",
    "target\n",
    "\n",
    "X = logs_df[features]\n",
    "X.head()\n",
    "\n",
    "y = logs_df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=324)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "\n",
    "# std scaler jest szkolony tylko na train\n",
    "# wszelkie przetwarzanie testu na podstawie regół, znalezioych dla train, także dla pre-process\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate_model(models, model_id=0, lr=0.001, batch_size=1024, epochs=3500, patience=0):\n",
    "\n",
    "    # Keras model\n",
    "    k_model = Sequential()\n",
    "    # 1st layer\n",
    "    #k_model.add(Dense(units=512, kernel_initializer=VarianceScaling, input_shape=X.shape[0], activation=None))\n",
    "    k_model.add(Dense(128, activation=None, input_shape=(5,)))\n",
    "    k_model.add(BatchNormalization())\n",
    "    k_model.add(Activation(\"relu\"))\n",
    "    k_model.add(Dropout(rate=0.1))\n",
    "    # 2nd layer\n",
    "    k_model.add(Dense(64, activation=None))\n",
    "    k_model.add(BatchNormalization())\n",
    "    k_model.add(Activation(\"relu\"))\n",
    "    k_model.add(Dropout(rate=0.1))\n",
    "    # 3nd layer\n",
    "    k_model.add(Dense(16, activation=None))\n",
    "    k_model.add(BatchNormalization())\n",
    "    k_model.add(Activation(\"relu\"))\n",
    "    # 4nd layer\n",
    "    k_model.add(Dense(1, activation=None))\n",
    "    k_model.add(BatchNormalization())\n",
    "    k_model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "    k_model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(lr=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "    # callbacks\n",
    "    callbacks = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=patience,\n",
    "                              verbose=0, mode='auto')\n",
    "\n",
    "    # Train\n",
    "    history = k_model.fit(X_train_scaled, y=y_train.values, epochs=epochs,\n",
    "                          batch_size=batch_size, validation_split=0.25,\n",
    "                          callbacks=[callbacks], verbose=0)\n",
    "\n",
    "    # Plot training history\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    sns.set_style(\"darkgrid\")\n",
    "\n",
    "    def plot_accuracy_and_loss(trained_model, test_accuracy):\n",
    "        \n",
    "        global conn\n",
    "        global cur\n",
    "\n",
    "        validation = False\n",
    "\n",
    "        hist = trained_model.history\n",
    "        acc = hist['acc']\n",
    "        loss = hist['loss']\n",
    "        try:\n",
    "            val_acc = hist['val_acc']\n",
    "            val_loss = hist['val_loss']\n",
    "            validation = True\n",
    "        except KeyError as e:\n",
    "            print(\"No validation data defined, showing only training set hostory\")\n",
    "        epochsw = range(1, len(acc)+1)\n",
    "\n",
    "        fig, ax = plt.subplots(1,2, figsize=(14,6))\n",
    "\n",
    "        plt.suptitle(\"Model_id={0}: lr={1}, batch_size={2}, epochs={3}, test_accuracy={4: .10f}\" \\\n",
    "                     .format(model_id, lr, batch_size, epochs, test_accuracy), color='grey', fontsize=20)\n",
    "\n",
    "        ax[0].tick_params(colors=\"grey\")\n",
    "        ax[0].plot(epochsw, acc, 'g', label='Training accuracy')\n",
    "        if validation:\n",
    "            ax[0].plot(epochsw, val_acc, 'r', label='Validation accuracy')\n",
    "        ax[0].set_ylabel('Accuracy', color='grey', fontsize=12)\n",
    "        ax[0].set_title('Training and validation accuracy', color='grey', fontsize=16)\n",
    "        ax[0].set_xlabel('Epochs', color='grey', fontsize=12)\n",
    "\n",
    "\n",
    "        ax[0].legend()\n",
    "        ax[0].grid(True)\n",
    "\n",
    "        ax[1].tick_params(colors=\"grey\")\n",
    "        ax[1].plot(epochsw, loss, 'g', label='Training cost')\n",
    "        if validation:\n",
    "            ax[1].plot(epochsw, val_loss, 'r', label='Validation cost')\n",
    "        ax[1].legend()\n",
    "        ax[1].set_title('Training and validation loss', color='grey', fontsize=16)\n",
    "        ax[1].set_xlabel('Epochs', color='grey', fontsize=12)\n",
    "        ax[1].set_ylabel('Loss', color='grey', fontsize=12)\n",
    "        ax[1].grid(True)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # Evaluate & Plot\n",
    "    score_test = k_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    test_loss = score_test[0]\n",
    "    test_accuracy = score_test[1]\n",
    "\n",
    "    # Print evaluation results on test dataset\n",
    "    print(\"model_id_{}: lr={}, batch_size={}, epochs={}, patience={}\" \\\n",
    "          .format(model_id, lr, batch_size, epochs, patience))\n",
    "    print('Test loss:', test_loss)\n",
    "    print('Test accuracy:', test_accuracy)\n",
    "\n",
    "    # Zapisanie do dictionary\n",
    "    models[\"{}\".format(model_id)] = {\n",
    "        \"lr\": lr,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"patience\": patience\n",
    "    }\n",
    "\n",
    "    try:\n",
    "\n",
    "        # insert statement\n",
    "        sql_statement = \"\"\"\n",
    "            insert into dl_models (python_model_id, lr, batch_size, epochs, test_loss, test_accuracy, patience) values ({}, {}, {}, {}, {}, {}, {})\n",
    "        \"\"\".format(model_id, lr, batch_size, epochs, test_loss, test_accuracy, patience)\n",
    "\n",
    "        # execute and commit\n",
    "        cur.execute(sql_statement)\n",
    "        conn.commit()\n",
    "\n",
    "    except Exception:\n",
    "        print(\"Cannot save model parameters to the database\")\n",
    "        print(str(Exception))\n",
    "\n",
    "        print(\"Trying to re-establish database connection...\")\n",
    "        try:\n",
    "            cur.close()\n",
    "            conn.close()\n",
    "        except:\n",
    "            print(\"Cannot close current connection\")\n",
    "\n",
    "        # Wait 5s and try re-establish connection\n",
    "        sleep(5)\n",
    "\n",
    "        try:\n",
    "            conn = psycopg2.connect(host='192.168.0.101', user='bartek', password='Aga', database='logs', port=5432)\n",
    "            conn.set_client_encoding('UTF8')\n",
    "            cur = conn.cursor()\n",
    "            print(\"New connection has been established\")\n",
    "        except:\n",
    "            print (\"I am unable to connect to the database.\")\n",
    "\n",
    "            sleep(180)\n",
    "            try:\n",
    "                conn = psycopg2.connect(host='192.168.0.101', user='bartek', password='Aga', database='logs', port=5432)\n",
    "                conn.set_client_encoding('UTF8')\n",
    "                cur = conn.cursor()\n",
    "                print(\"New connection has been established\")\n",
    "            except:\n",
    "                print (\"I am unable to connect to the database, quitting...\")\n",
    "                sys.exit()\n",
    "\n",
    "        cur.execute(sql_statement)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "\n",
    "    # Best model?\n",
    "    current_best =  models.get(\"best\", None)\n",
    "    if current_best != None and current_best[\"test_accuracy\"] >= test_accuracy:\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        # aktualizacja best\n",
    "        models[\"best\"] = {\n",
    "            \"model_id\": model_id,\n",
    "            \"lr\": lr,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"epochs\": epochs,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy\": test_accuracy,\n",
    "            \"patience\": patience\n",
    "        }\n",
    "        # nowy wykres z historią uczenia\n",
    "        plot_accuracy_and_loss(history,  test_accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary z modelami\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Fitting model 1695 / 1730\n",
      "model_id_1695: lr=0.0001, batch_size=16, epochs=25000, patience=3\n",
      "Test loss: 0.09569342031543909\n",
      "Test accuracy: 0.9773043997729652\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1696 / 1730\n",
      "model_id_1696: lr=0.0001, batch_size=16, epochs=25000, patience=5\n",
      "Test loss: 0.0933627730393799\n",
      "Test accuracy: 0.9637666733146735\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1697 / 1730\n",
      "model_id_1697: lr=0.0001, batch_size=16, epochs=25000, patience=30\n",
      "Test loss: 0.0671104288895648\n",
      "Test accuracy: 0.9749153892096357\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1698 / 1730\n",
      "model_id_1698: lr=0.0001, batch_size=16, epochs=25000, patience=50\n",
      "Test loss: 0.07180620412201894\n",
      "Test accuracy: 0.9858650209157087\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1699 / 1730\n",
      "model_id_1699: lr=0.0001, batch_size=32, epochs=25000, patience=3\n",
      "Test loss: 0.06191434822613182\n",
      "Test accuracy: 0.9822815050885138\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1700 / 1730\n",
      "model_id_1700: lr=0.0001, batch_size=32, epochs=25000, patience=5\n",
      "Test loss: 0.07091575849852476\n",
      "Test accuracy: 0.9779016524108312\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1701 / 1730\n",
      "model_id_1701: lr=0.0001, batch_size=32, epochs=25000, patience=30\n",
      "Test loss: 0.03833218635674162\n",
      "Test accuracy: 0.9798924945251841\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1702 / 1730\n",
      "model_id_1702: lr=0.0001, batch_size=32, epochs=25000, patience=50\n",
      "Test loss: 0.043127007061578876\n",
      "Test accuracy: 0.9753135576348796\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1703 / 1730\n",
      "model_id_1703: lr=0.0001, batch_size=64, epochs=25000, patience=3\n",
      "Test loss: 0.05109815942221801\n",
      "Test accuracy: 0.9814851680481645\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1704 / 1730\n",
      "model_id_1704: lr=0.0001, batch_size=64, epochs=25000, patience=5\n",
      "Test loss: 0.05566512096451498\n",
      "Test accuracy: 0.9862631893409526\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1705 / 1730\n",
      "model_id_1705: lr=0.0001, batch_size=64, epochs=25000, patience=30\n",
      "Test loss: 0.03585941510331742\n",
      "Test accuracy: 0.9826796735137576\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1706 / 1730\n",
      "model_id_1706: lr=0.0001, batch_size=64, epochs=25000, patience=50\n",
      "Test loss: 0.03531938277684833\n",
      "Test accuracy: 0.9822815050885138\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1707 / 1730\n",
      "model_id_1707: lr=0.0001, batch_size=128, epochs=25000, patience=3\n",
      "Test loss: 0.09361611713386261\n",
      "Test accuracy: 0.9848695998525989\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1708 / 1730\n",
      "model_id_1708: lr=0.0001, batch_size=128, epochs=25000, patience=5\n",
      "Test loss: 0.05427074325279294\n",
      "Test accuracy: 0.9836750945768673\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1709 / 1730\n",
      "model_id_1709: lr=0.0001, batch_size=128, epochs=25000, patience=30\n",
      "Test loss: 0.0323228568836925\n",
      "Test accuracy: 0.9848695998525989\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1710 / 1730\n",
      "model_id_1710: lr=0.0001, batch_size=128, epochs=25000, patience=50\n",
      "Test loss: 0.03286602116843844\n",
      "Test accuracy: 0.984471431427355\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1711 / 1730\n",
      "model_id_1711: lr=0.0001, batch_size=256, epochs=25000, patience=3\n",
      "Test loss: 0.07938610226592291\n",
      "Test accuracy: 0.9822815048986523\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1712 / 1730\n",
      "model_id_1712: lr=0.0001, batch_size=256, epochs=25000, patience=5\n",
      "Test loss: 0.0712919376646644\n",
      "Test accuracy: 0.985068684065221\n",
      "Cannot save model parameters to the database\n",
      "<class 'Exception'>\n",
      "Trying to re-establish database connection...\n",
      "Cannot close current connection\n",
      "New connection has been established\n",
      "\n",
      "\n",
      "Fitting model 1713 / 1730\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-92934109d32c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nFitting model {} / {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkombinacje\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 fit_and_evaluate_model(models, model_id, lr=lr,\n\u001b[0;32m---> 20\u001b[0;31m                                        batch_size=batch_size, epochs=epochs, patience=patience)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nBest model:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-046113ad0eff>\u001b[0m in \u001b[0;36mfit_and_evaluate_model\u001b[0;34m(models, model_id, lr, batch_size, epochs, patience)\u001b[0m\n\u001b[1;32m     35\u001b[0m     history = k_model.fit(X_train_scaled, y=y_train.values, epochs=epochs,\n\u001b[1;32m     36\u001b[0m                           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                           callbacks=[callbacks], verbose=0)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Plot training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grid search\n",
    "\n",
    "lrs = [0.0001]\n",
    "epochss = [25000]\n",
    "batch_sizes = [16, 32, 64, 128, 256, 516, 1024, 2048, 4096]\n",
    "patiences=[3, 5, 30, 50]\n",
    "\n",
    "model_id = 1694\n",
    "\n",
    "kombinacje = len(lrs) * len(epochss) * len(batch_sizes) * len(patiences) + model_id\n",
    "\n",
    "for lr in lrs:\n",
    "    for epochs in epochss:\n",
    "        for batch_size in batch_sizes:\n",
    "            for patience in patiences:\n",
    "\n",
    "                model_id += 1\n",
    "                print(\"\\n\\nFitting model {} / {}\".format(model_id, kombinacje))\n",
    "                fit_and_evaluate_model(models, model_id, lr=lr,\n",
    "                                       batch_size=batch_size, epochs=epochs, patience=patience)\n",
    "\n",
    "print(\"\\n\\nBest model:\")\n",
    "print(models[\"best\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRZERWANE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
